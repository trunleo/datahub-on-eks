{"cells":[{"cell_type":"markdown","id":"502dab76","metadata":{},"source":["# dim_source_store_sale"]},{"cell_type":"markdown","id":"5cbf4a14","metadata":{},"source":["## Import libraries"]},{"cell_type":"code","execution_count":1,"id":"1655fdfd","metadata":{},"outputs":[],"source":["from pyspark import SparkConf, SparkContext\n","from pyspark.sql import SparkSession\n","import pyspark.sql.functions as F\n","from pyspark.sql.functions import udf\n","from pyspark.sql.functions import udf,upper,lit,monotonically_increasing_id, row_number,col\n","from pyspark.sql.types import StringType, LongType, DecimalType, TimestampType, DateType, BooleanType\n","import pandas as pd\n","import numpy as np\n","import datetime\n","import datetime\n","from pyspark.sql.utils import AnalysisException\n","from pyspark.sql.window import Window\n","from yody_function.deltalake import upsert_deltalake\n","from yody_function.support_function import last_modify_time, top_modify_time, print_log\n","from yody_function.bigquery import upsert_bigquery\n","from datetime import datetime, timedelta"]},{"cell_type":"markdown","id":"e6f57999","metadata":{},"source":["## Load config"]},{"cell_type":"code","execution_count":2,"id":"548b65fb","metadata":{},"outputs":[],"source":["ENV = 'prod'\n","HDFS_MASTER = 'gs://yody-lakehouse'\n","HDFS_MASTER_BAKUP = 'gs://yody-backup'\n","SPARK_HOME = 'yarn'\n","DATA_SOURCE = '/lading-zone/'\n","DATA_STORE = f'/dwh/{ENV}/dim/'"]},{"cell_type":"markdown","id":"dd190a9d","metadata":{},"source":["## Initializing Spark Session"]},{"cell_type":"code","execution_count":3,"id":"4fc7226a","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","24/06/19 09:11:43 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n","24/06/19 09:11:43 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n","24/06/19 09:11:43 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n","24/06/19 09:11:43 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n"]}],"source":["sparkSession = SparkSession\\\n",".builder\\\n",".appName(\"dim_soure_store_sale\")\\\n",".master(SPARK_HOME)\\\n",".config(\"spark.cores.max\", '2')\\\n",".config(\"spark.executor.memory\", '2g')\\\n",".config(\"spark.sql.debug.maxToStringFields\", 255)\\\n",".config(\"spark.jars\", \"gs://yody-lakehouse/job/jar_file/delta-core_2.12-1.0.1.jar,gs://spark-lib/bigquery/spark-bigquery-with-dependencies_2.12-0.28.0.jar\")\\\n",".config(\"spark.sql.parquet.enableVectorizedReader\", \"false\")\\\n",".getOrCreate()"]},{"cell_type":"markdown","id":"888df533","metadata":{},"source":["### Connect to HDFS"]},{"cell_type":"code","execution_count":4,"id":"1a110fdb","metadata":{},"outputs":[],"source":["def apply_columns(df, columns, func=lambda x: F.col(x), naming_func=lambda x: x):\n","    for col in columns:\n","        if col not in df.columns:\n","            raise Exception(f\"not found column {str(col)} in {df.columns}\")\n","        else:\n","            df = df.withColumn(naming_func(col), func(col))\n","    return df\n","\n","def begin_date_store(sparkSession, env, _type = \"normal\"):\n","    \"\"\"\n","        type: [\"normal\", \"incremental\", \"overwrite\"]\n","    \"\"\"\n","    path_save_table = f\"gs://yody-lakehouse/staging/unicorn/{env}/begin_store_mapping\"\n","    columns_key = [\"store_id\"]\n","        \n","    if(_type == 'normal'):\n","        pass\n","    else:\n","        df_ = sparkSession.read.parquet(HDFS_MASTER + f\"/lading-zone/prod/prod_order_service/orders/*\")\\\n","            .filter(\"(status == 'finished') and (channel == 'POS')\")\\\n","            .filter(\"is_deleted == 0\")\\\n","            .groupby(\"store_id\").agg(\n","                F.min(\"created_date\").alias(\"begin_date\")\n","            )\\\n","            .withColumn(\"begin_date\", \n","                        F.when(F.col(\"store_id\") == 192, \"2022-06-07 04:07:08.0\")\n","                        .when(F.col(\"store_id\") == 207, \"2022-11-15 13:13:02.0\")\n","                        .otherwise(F.col(\"begin_date\"))\n","            )\n","        \n","        if(_type == 'overwrite'):\n","            upsert_deltalake(\n","                sparkSession,\n","                df_upsert=df_,\n","                path_table=path_save_table,\n","                columns_key=columns_key,\n","                mode=\"overwrite\"\n","            )\n","        if(_type == 'incremental'):\n","            df_old = sparkSession.read.format(\"delta\").load(path_save_table)\\\n","                .withColumnRenamed(\"begin_date\", \"begin_date_old\")\n","            df_.printSchema()\n","            df_ = df_.join(df_old, [\"store_id\"], \"left\")\\\n","                .filter(\"begin_date_old is null\")\\\n","                .select(\"store_id\", \"begin_date\")\\\n","                .cache()\n","            print_log(f\"so luong cua hang moi {df_.count()}\")\n","            \n","            df_.printSchema()\n","            upsert_deltalake(\n","                sparkSession = sparkSession,\n","                df_upsert=df_,\n","                path_table=path_save_table,\n","                columns_key=columns_key,\n","                mode=\"upsert\"\n","            )\n","        \n","    return sparkSession.read.format(\"delta\").load(path_save_table)"]},{"cell_type":"markdown","id":"73c5c963","metadata":{},"source":["### read data"]},{"cell_type":"code","execution_count":5,"id":"b9bc926e","metadata":{"scrolled":true},"outputs":[{"name":"stderr","output_type":"stream","text":["24/06/19 09:12:12 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:12:27 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:12:42 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:12:57 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:13:12 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:13:27 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:13:42 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:13:57 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:14:12 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:14:27 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:14:42 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:14:57 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:15:12 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:15:27 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:15:42 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:15:57 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:16:12 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:16:27 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:16:42 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:16:57 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:17:12 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:17:27 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:17:42 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:17:57 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:18:12 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:18:27 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:18:42 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:18:57 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:19:12 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:19:27 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:19:42 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:19:57 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:20:12 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:20:27 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:20:42 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:20:57 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:21:12 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:21:27 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:21:42 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:21:57 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:22:12 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:22:27 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:22:42 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:22:57 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:23:12 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:23:27 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:23:42 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:23:57 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:24:12 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:24:27 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:24:42 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:24:57 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:25:12 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:25:27 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:25:42 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:25:57 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:26:12 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:26:27 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:26:42 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:26:57 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:27:12 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:27:27 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:27:42 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:27:57 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:28:12 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:28:27 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:28:42 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:28:57 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:29:12 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:29:27 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:29:42 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:29:57 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:30:12 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:30:27 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:30:42 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:30:57 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:31:12 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:31:27 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:31:42 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:31:57 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:32:12 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:32:27 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:32:42 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:32:57 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:33:12 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:33:27 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:33:42 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:33:57 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:34:12 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:34:27 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:34:42 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:34:57 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:35:12 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:35:27 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:35:42 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:35:57 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:36:12 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","24/06/19 09:36:27 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n","                                                                                \r"]}],"source":["df_department = sparkSession\\\n",".read\\\n",".parquet(HDFS_MASTER + f\"/lading-zone/{ENV}/{ENV}_account_service/department\")\n","\n","df_store = sparkSession\\\n",".read\\\n",".parquet(HDFS_MASTER + f\"/lading-zone/{ENV}/{ENV}_core_service/store\")\n","\n","df_source = sparkSession\\\n",".read\\\n",".parquet(HDFS_MASTER + f\"/lading-zone/{ENV}/{ENV}_core_service/source\")\n","\n","df_city = sparkSession\\\n",".read\\\n",".parquet(HDFS_MASTER + f\"/lading-zone/{ENV}/{ENV}_content_service/city\")\n","\n","df_economic_zone = sparkSession\\\n",".read\\\n",".parquet(HDFS_MASTER + f\"/lading-zone/{ENV}/{ENV}_core_service/economic_zone\")\n","\n","df_manager = sparkSession\\\n",".read\\\n",".option('header', 'true')\\\n",".csv('gs://yody-lakehouse/lading-zone/google_sheet/manager_by_store/final.csv')\n","\n","df_trainer = sparkSession\\\n",".read\\\n",".option('header', 'true')\\\n",".csv('gs://yody-lakehouse/lading-zone/google_sheet/data_store/final.csv')\n","\n","df_rsm = sparkSession\\\n",".read\\\n",".option('header', 'true')\\\n",".csv('gs://yody-lakehouse/lading-zone/google_sheet/map_asm/final.csv')"]},{"cell_type":"code","execution_count":6,"id":"b6573a3a","metadata":{},"outputs":[],"source":["if(ENV == \"dev\"):\n","    df_fake = pd.read_csv(\"https://docs.google.com/spreadsheet/ccc?key=1owWynqISRn4p4zowOjSffI6kihV7wtx9Cxaf3ZLbhwg&output=csv\")\n","    df_fake = sparkSession.createDataFrame(df_fake)\n","    df_source = df_source.drop(*[\"department_id\"])\\\n","        .join(df_fake, \"id\", \"left\")"]},{"cell_type":"code","execution_count":7,"id":"8592e875","metadata":{},"outputs":[],"source":["# last\n","df_department = last_modify_time(df_department, \"id\", \"updated_date\").filter(\"is_deleted == 0\")\n","df_store = last_modify_time(df_store, \"id\", \"updated_date\").filter(\"is_deleted == 0\")\n","df_source = last_modify_time(df_source, \"id\", \"updated_date\").filter(\"is_deleted == 0\")\n","df_city = last_modify_time(df_city, \"id\", \"updated_date\").filter(\"is_deleted == 0\")\n","df_economic_zone = last_modify_time(df_economic_zone, \"id\", \"updated_date\").filter(\"is_deleted == 0\")\n","\n","# select\n","df_department = df_department.select(\"id\", \"parent_id\", \"name\", 'updated_date', 'is_deleted')"]},{"cell_type":"markdown","id":"81d73ac3","metadata":{},"source":["#### begin_date_store"]},{"cell_type":"code","execution_count":8,"id":"a01980a3","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["root\n"," |-- store_id: long (nullable = true)\n"," |-- begin_date: string (nullable = true)\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["2024-06-19 09:39:35.258 INFO - so luong cua hang moi 0\n","root\n"," |-- store_id: long (nullable = true)\n"," |-- begin_date: string (nullable = true)\n","\n","2024-06-19 09:39:35.489 INFO - upsert table\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["2024-06-19 09:39:55.095 INFO - vacuum - 0\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Deleted 0 files and directories in a total of 1 directories.\n"]}],"source":["df_begin = begin_date_store(sparkSession, ENV, \"incremental\")\n","\n","df_begin = df_begin\\\n",".withColumn(\"source_store_key\", F.concat(F.lit(\"ST\"), F.col(\"store_id\")))\\\n",".withColumn(\"begin_date_07\", F.col(\"begin_date\") + F.expr(\"INTERVAL 7 HOURS\"))\\\n",".select(\"source_store_key\", \"begin_date_07\")"]},{"cell_type":"markdown","id":"a1f9506b","metadata":{},"source":["#### manager_by_store"]},{"cell_type":"code","execution_count":9,"id":"273ee72c","metadata":{},"outputs":[],"source":["df_manager = df_manager.filter(F.col('TỈNH')!='TỈNH')\n","raw_cols = [i for i in df_manager.columns if i.strip().lower() in ('tỉnh', 'asm_name')]\n","\n","df_manager = apply_columns(df_manager, \n","                           columns=raw_cols,\n","                           func=F.upper,\n","                           naming_func=lambda x: x.strip().lower()\n","                          )\n","df_manager = df_manager\\\n",".withColumn('city_name', F.upper(F.trim('tỉnh')))\\\n",".withColumn('asm_name', F.upper(F.trim('asm_name')))\\\n",".select('city_name', 'asm_name')\n","\n","df_manager = df_manager.dropDuplicates()"]},{"cell_type":"code","execution_count":10,"id":"ba6bd118","metadata":{},"outputs":[],"source":["# change region\n","df_rsm = df_rsm.filter(F.col('id').cast('int').isNotNull())\n","raw_cols = [i for i in df_rsm.columns if i.strip().lower() in ('id', 'rsm_name', 'region')]\n","\n","df_rsm = df_rsm\\\n",".withColumn('city_id', F.col('id').cast('int'))\\\n",".withColumn('rsm_name', F.upper(F.trim('rsm_name')))\\\n",".withColumn('region', F.when(F.lower('region')=='none', F.lit(None).cast('string')).otherwise(F.col('region')))\\\n",".withColumn('region', F.upper(F.trim(F.col(\"region\"))))\\\n",".select('city_id', 'rsm_name', 'region')\n","df_rsm = df_rsm.dropDuplicates()"]},{"cell_type":"markdown","id":"9874d3a3","metadata":{},"source":["#### data_store"]},{"cell_type":"code","execution_count":11,"id":"341183e0","metadata":{},"outputs":[],"source":["df_trainer = df_trainer.filter('CAST(STT AS INT) IS NOT NULL')\n","raw_cols = [i for i in df_trainer.columns if i.strip().lower() in ('store_name', 'trainer_code')]\n","\n","df_trainer = apply_columns(df_trainer, \n","                           columns=raw_cols,\n","                           func=lambda x: F.upper(x), \n","                           naming_func=lambda x: x.strip().lower()\n","                          )\n","\n","clean_string = lambda x: F.upper(F.trim(x))\n","df_trainer = df_trainer\\\n",".withColumn('source_store_name', clean_string('store_name'))\\\n",".withColumn('trainer_code', \n","            F.when(F.expr('lower(trainer_code) = \"none\"'), F.lit(None).cast('string')).otherwise(F.col('trainer_code')))\\\n",".withColumn('trainer_code', clean_string('trainer_code'))\\\n",".select('source_store_name', 'trainer_code')\n","\n","df_trainer = df_trainer.dropDuplicates()"]},{"cell_type":"markdown","id":"637c35cf","metadata":{},"source":["## Transformations"]},{"cell_type":"markdown","id":"40d44198","metadata":{},"source":["### Preprocess on source data"]},{"cell_type":"markdown","id":"beb23a87","metadata":{},"source":["#### Add `source_store_id`, `source_store_name`, `source_store_key`, `source_store_type`, and `type`"]},{"cell_type":"code","execution_count":12,"id":"4a36a23f","metadata":{},"outputs":[],"source":["df_source = df_source\\\n",".withColumnRenamed('id', 'source_store_id')\\\n",".withColumnRenamed('name', 'source_store_name')\\\n",".withColumn('source_store_key', F.concat(F.lit(\"SO\"), F.col(\"source_store_id\")))\\\n",".withColumn('source_store_type', F.lit(''))\\\n",".withColumn('type', F.lit('source'))\\\n",".withColumn('source_store_code', F.col('code'))\\\n",".withColumn('longitude', F.lit(None).cast(StringType()))"]},{"cell_type":"code","execution_count":13,"id":"1abcbf90","metadata":{},"outputs":[],"source":["df_store = df_store\\\n",".withColumnRenamed('id', 'source_store_id')\\\n",".withColumnRenamed('name', 'source_store_name')\\\n",".withColumn('source_store_key', F.concat(F.lit(\"ST\"), F.col(\"source_store_id\")))\\\n",".withColumn('source_store_type', F.col('type'))\\\n",".withColumn('type', F.lit('store'))\\\n",".withColumn('source_store_code', F.col('code'))\\\n",".withColumn('city_name', F.trim(F.upper('city_name')))\\\n",".withColumn('ward_name', F.trim(F.upper('ward_name')))\\\n",".withColumn('district_name', F.trim(F.upper('district_name')))"]},{"cell_type":"markdown","id":"7696147c","metadata":{},"source":["#### Add missing columns for df_source\n","\n","- Add `square` column with default **0** value and convert to the **DecimalType(10, 2)** datatype.\n","\n","- Add `city_id`, `rank_name`, and `is_saleable` columns with default **null** value.\n","\n","- Add `status` based on the below condition:\n","\n","    - If **is_active is True** then **status = 'active'**.\n","    \n","    - Otherwise **status = 'inactive'**."]},{"cell_type":"code","execution_count":14,"id":"417c2252","metadata":{},"outputs":[],"source":["df_source = df_source\\\n",".withColumn('square', F.lit(0).cast(DecimalType(precision=10, scale=2)))\\\n",".withColumn('city_id', F.lit(None).cast(LongType()))\\\n",".withColumn('rank_name', F.lit(None).cast(StringType()))\\\n",".withColumn('is_saleable', F.lit(None).cast(BooleanType()))\\\n",".withColumn('latitude', F.lit(None).cast(StringType()))\\\n",".withColumn('longtitude', F.lit(None).cast(StringType()))\\\n",".withColumn('city_name', F.lit(None).cast(StringType()))\\\n",".withColumn('ward_name', F.lit(None).cast(StringType()))\\\n",".withColumn('district_name', F.lit(None).cast(StringType()))\\\n",".withColumn('asm_name', F.lit(None).cast(StringType()))\\\n",".withColumn('rsm_name', F.lit(None).cast(StringType()))\\\n",".withColumn('trainer_code', F.lit(None).cast(StringType()))\n","\n","\n","df_source = df_source\\\n",".withColumn('status', F.when(F.col('is_active')==F.lit(True), F.lit('active')).otherwise(F.lit('inactive')))"]},{"cell_type":"markdown","id":"10109cc3","metadata":{},"source":["#### Correct `square` and `status` columns for df_store"]},{"cell_type":"code","execution_count":15,"id":"a6bffb14","metadata":{},"outputs":[],"source":["df_store = df_store\\\n",".withColumn('square', F.col('square').cast(DecimalType(precision=10, scale=2)))\\\n",".withColumn('status', F.lower(F.col('status')))\n","\n","df_store = df_store.fillna(0, subset=['square'])"]},{"cell_type":"markdown","id":"5a94cb91","metadata":{},"source":["#### Join to get df_city_region"]},{"cell_type":"code","execution_count":16,"id":"4da20a7e","metadata":{},"outputs":[],"source":["df_economic_zone = df_economic_zone\\\n",".withColumnRenamed('id', 'economic_zone_id')\\\n",".withColumnRenamed('name', 'region')\\\n",".withColumn('region', F.upper(F.trim(F.col(\"region\"))))\n","\n","df_city = df_city.withColumnRenamed('id', 'city_id')\n","\n","# change region\n","df_city_region = df_city.join(df_rsm, ['city_id'], 'left')#(df_economic_zone, [\"economic_zone_id\"])\n","df_city_region = df_city_region\\\n",".select('city_id', 'region')\\\n",".filter(\"city_id is not null\")\\\n",".dropDuplicates()"]},{"cell_type":"markdown","id":"b799047b","metadata":{},"source":["#### Clean string field of 4 dataframes\n","\n","- Replace string '\\x00' by ''(empty string).\n","\n","- Clean on the `name` for **df_department**, \n","- Clean on the `source_store_name` for **df_source**,\n","- Clean on the `source_store_name` and `rank_name` **df_store**.\n","- Clean on the `region` for **df_city_region**."]},{"cell_type":"code","execution_count":17,"id":"b930406c","metadata":{},"outputs":[],"source":["clean_name_rule = lambda name: F.upper(F.regexp_replace(F.col(name), '\\x00', ''))\n","\n","df_department = df_department.withColumn('name', clean_name_rule('name'))\n","\n","df_source = df_source.withColumn('source_store_name', clean_name_rule('source_store_name'))\n","\n","df_store = df_store\\\n",".withColumn('source_store_name', clean_name_rule('source_store_name'))\\\n",".withColumn('rank_name', clean_name_rule('rank_name'))\n","\n","df_city_region = df_city_region.withColumn('region', clean_name_rule('region'))"]},{"cell_type":"code","execution_count":18,"id":"7896d38e","metadata":{},"outputs":[],"source":["df_store = df_store\\\n",".join(df_manager, ['city_name'], 'left')\\\n",".join(df_trainer, ['source_store_name'], 'left')\\\n",".join(df_rsm, ['city_id'], 'left')\n","\n","mapping_sheet_cond = F.col('source_store_type') == 'store'\n","df_store = df_store\\\n",".withColumn('asm_name', F.when(mapping_sheet_cond, F.col('asm_name')).otherwise(F.lit(None).cast('string')))\\\n",".withColumn('rsm_name', F.when(mapping_sheet_cond, F.col('rsm_name')).otherwise(F.lit(None).cast('string')))\\\n",".withColumn('trainer_code', F.when(mapping_sheet_cond, F.col('trainer_code')).otherwise(F.lit(None).cast('string')))"]},{"cell_type":"markdown","id":"71845f00","metadata":{},"source":["### Process target data\n","\n","1. Union to the united form of df_source_store\n","\n","2. Join with df_begin"]},{"cell_type":"code","execution_count":19,"id":"03499c28","metadata":{},"outputs":[],"source":["union_selected_cols = [\n","    'source_store_key', \n","    'source_store_id', \n","    'source_store_code',\n","    'source_store_name', \n","    'source_store_type',\n","    'department_id',\n","    'city_id',\n","    'type',\n","    'status',\n","    'is_saleable', \n","    'rank_name',\n","    'square',\n","    'latitude',\n","    'longitude',\n","    'city_name',\n","    'ward_name', \n","    'district_name',\n","    'is_deleted',\n","    'asm_name',\n","    'trainer_code',\n","    'rsm_name'\n","]"]},{"cell_type":"code","execution_count":20,"id":"4cbcff6f","metadata":{},"outputs":[],"source":["df_source = df_source.select(union_selected_cols)\n","df_store = df_store.select(union_selected_cols)"]},{"cell_type":"code","execution_count":21,"id":"60fe6cf9","metadata":{},"outputs":[],"source":["df_source_store_trans = df_source.union(df_store)\n","df_source_store_trans = df_source_store_trans.join(df_begin, \"source_store_key\", \"left\")\n","df_source_store_trans = df_source_store_trans\\\n",".fillna(\"1900-01-01\", subset=[\"begin_date_07\"])\\\n",".withColumn(\"begin_date_07\", F.col(\"begin_date_07\").cast(DateType()))"]},{"cell_type":"markdown","id":"7a8ea09e","metadata":{},"source":["#### Create level dataframe indicated the company's schema\n","\n","- Try to left join 6 times for finding 3 main levels of each department.\n","\n","- Could not modify the below block due to implicited 6 dataframe's names."]},{"cell_type":"code","execution_count":22,"id":"d011c7b6","metadata":{},"outputs":[],"source":["df_lv = df_department.alias(\"d0\")\\\n","    .join(df_department.alias(\"d1\"), col(\"d0.parent_id\") == col(\"d1.id\"), \"left\")\\\n","    .join(df_department.alias(\"d2\"), col(\"d1.parent_id\") == col(\"d2.id\"), \"left\")\\\n","    .join(df_department.alias(\"d3\"), col(\"d2.parent_id\") == col(\"d3.id\"), \"left\")\\\n","    .join(df_department.alias(\"d4\"), col(\"d3.parent_id\") == col(\"d4.id\"), \"left\")\\\n","    .join(df_department.alias(\"d5\"), col(\"d4.parent_id\") == col(\"d5.id\"), \"left\")\\\n","    .join(df_department.alias(\"d6\"), col(\"d5.parent_id\") == col(\"d6.id\"), \"left\")\\\n","    .withColumn(\"department_lv1\", F.when(col(\"d6.parent_id\") == -1, col(\"d4.name\"))\n","                                    .when(col(\"d5.parent_id\") == -1, col(\"d3.name\"))\n","                                    .when(col(\"d4.parent_id\") == -1, col(\"d2.name\"))\n","                                    .when(col(\"d3.parent_id\") == -1, col(\"d1.name\"))\n","                                    .when(col(\"d2.parent_id\") == -1, col(\"d0.name\"))\n","                                    .otherwise(\"\")\n","    )\\\n","    .withColumn(\"department_lv2\", F.when(col(\"d6.parent_id\") == -1, col(\"d3.name\"))\n","                                    .when(col(\"d5.parent_id\") == -1, col(\"d2.name\"))\n","                                    .when(col(\"d4.parent_id\") == -1, col(\"d1.name\"))\n","                                    .when(col(\"d3.parent_id\") == -1, col(\"d0.name\"))\n","                                    .otherwise(\"\")\n","    )\\\n","    .withColumn(\"department_lv3\", F.when(col(\"d6.parent_id\") == -1, col(\"d2.name\"))\n","                                    .when(col(\"d5.parent_id\") == -1, col(\"d1.name\"))\n","                                    .when(col(\"d4.parent_id\") == -1, col(\"d0.name\"))\n","                                    .otherwise(\"\")\n","        )\\\n","    .withColumn(\"department_lv4\", F.when(col(\"d6.parent_id\") == -1, col(\"d1.name\"))\n","                                    .when(col(\"d5.parent_id\") == -1, col(\"d0.name\"))\n","                                    .otherwise(\"\")\n","    )\\\n","    .selectExpr(\"d0.id as department_id\", \"department_lv1\", \"department_lv2\", \"department_lv3\", \"department_lv4\")"]},{"cell_type":"markdown","id":"dc51ff5c","metadata":{},"source":["### Xử lý level"]},{"cell_type":"code","execution_count":23,"id":"a1c88668","metadata":{},"outputs":[],"source":["lv1_offline_cond = (F.col('department_lv1')=='HỆ THỐNG KINH DOANH OFFLINE') | (F.col('department_lv1')=='HT KD OFFLINE')\n","lv1_online_cond = (F.col('department_lv1')=='HỆ THỐNG KINH DOANH ONLINE') | (F.col('department_lv1')=='HT KD ONLINE')\n","online_cond = F.col('department_lv2') == 'ONLINE'\n","ecom_cond = F.col('department_lv2') == 'ECOM'\n","selected_cols = [\"department_id\", \"department_lv1\", \"department_lv2\", \"department_lv3\"]\n","\n","df_lv_off = df_lv.filter(lv1_offline_cond)\\\n","                 .withColumn('department_lv1', F.lit('KINH DOANH OFFLINE'))\\\n","                 .select(selected_cols)\n","\n","df_lv_onl = df_lv.filter(lv1_online_cond)\\\n","                 .withColumn('department_lv1', F.when(online_cond, 'KINH DOANH ONLINE')\\\n","                                                .when(ecom_cond, 'E - COMMERCE')\\\n","                                                .otherwise(F.col('department_lv2')))\\\n","                 .withColumn('department_lv2', F.col('department_lv3'))\\\n","                 .withColumn('department_lv3', F.col('department_lv4'))\\\n","                 .select(selected_cols)\n","\n","df_lv_oth = df_lv.filter(~(lv1_online_cond | lv1_offline_cond))\\\n","                 .select(selected_cols)\n","\n","df_lv = df_lv_off.union(df_lv_onl).union(df_lv_oth)"]},{"cell_type":"markdown","id":"163686f8","metadata":{},"source":["#### Joing to get department levels and city_region data"]},{"cell_type":"code","execution_count":24,"id":"5a3e2145","metadata":{},"outputs":[],"source":["df_source_store_trans = df_source_store_trans.join(df_lv, \"department_id\", \"left\")\n","df_source_store_trans = df_source_store_trans.join(df_city_region, \"city_id\", \"left\")"]},{"cell_type":"markdown","id":"20a68eb8","metadata":{},"source":["## Final output"]},{"cell_type":"markdown","id":"577ceb1b","metadata":{},"source":["### Upsert deltalake on HDFS"]},{"cell_type":"code","execution_count":25,"id":"8479a601","metadata":{},"outputs":[],"source":["# HDFS_MASTER+DATA_STORE+\"dim_source_store_sale\"\n","selected_cols = ['source_store_key', 'source_store_id', 'source_store_code', 'type', 'department_id', \"department_lv1\", \n","                 \"department_lv2\", \"department_lv3\", \"source_store_name\", \"source_store_type\", 'rank_name', \"region\", \n","                 \"status\", 'is_saleable', 'square', \"begin_date_07\", \"latitude\", \"longitude\", 'city_name', 'ward_name', \n","                 'district_name', \"is_deleted\", \"asm_name\", 'trainer_code', 'rsm_name']\n","dim_source_store_sale = df_source_store_trans.select(selected_cols).cache()"]},{"cell_type":"code","execution_count":null,"id":"c98fba8b","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["2024-06-19 09:41:14.503 INFO - upsert table\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["2024-06-19 09:42:08.921 INFO - vacuum - 0\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Deleted 7 files and directories in a total of 1 directories.\n"]}],"source":["path_table = HDFS_MASTER+DATA_STORE+\"dim_source_store_sale\"\n","columns_key = ['source_store_key']\n","\n","upsert_deltalake(sparkSession=sparkSession, \n","                 df_upsert=dim_source_store_sale, \n","                 path_table=path_table, \n","                 columns_key=columns_key,\n","                 #mode='upsert',\n","#                  mode='overwrite', truncate=True,\n","#                  vacuum_time = None\n","                )"]},{"cell_type":"markdown","id":"62ce1120","metadata":{},"source":["### Upsert bigquery"]},{"cell_type":"code","execution_count":null,"id":"e5f6dc54","metadata":{},"outputs":[],"source":["json_info = {\n","    \"project_id\": \"yody-data-platform\",\n","    \"dataset\": f\"{ENV}_yody_analytics\",\n","    \"table_name\": \"dim_source_store_sale\"\n","}\n","columns_key = ['source_store_key']"]},{"cell_type":"code","execution_count":null,"id":"bb8f594d","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2024-06-19 09:42:50.099 INFO - write overwrite table - prod_yody_analytics.dim_source_store_sale\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/plain":["True"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["upsert_bigquery(df_upsert = dim_source_store_sale, \n","                json_info=json_info, \n","                columns_key=columns_key, \n","                truncate = True,\n","                mode='overwrite'\n","               )"]},{"cell_type":"markdown","id":"61873090","metadata":{},"source":["## Stop Session"]},{"cell_type":"code","execution_count":null,"id":"aa2d5511","metadata":{},"outputs":[],"source":["sparkSession.stop()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.15"}},"nbformat":4,"nbformat_minor":5}